apiVersion: v1
kind: Service
metadata:
  name: tpu-worker-svc
  labels:
    app: tpu-worker
spec:
  clusterIP: None
  selector:
    app: tpu-worker
---
apiVersion: batch/v1
kind: Job
metadata:
  name: multi-optimum-tpu
spec:
  backoffLimit: 0
  completions: 32
  parallelism: 32
  completionMode: Indexed
  template:
    metadata:
      labels:
        app: tpu-worker
    spec:
      subdomain: tpu-worker-svc
      restartPolicy: Never
      containers:
      - name: optimum-tpu
        image: gcr.io/tpu-vm-gke-testing/ricliu-optimum-tpu:20240716
        command: ["/bin/sh", "-c", "pip uninstall -y transformers && huggingface-cli login --token $HF_TOKEN && mkdir fork && cd fork && git clone 'https://${GIT_TOKEN}@github.com/wenxindongwork/optimum-tpu.git && cd optimum-tpu' && pip install -e . && python kubernetes/finetune_llama3_70b.py"]
        ports:
        - containerPort: 8471
        env:
        - name: HF_TOKEN
          valueFrom:
            secretKeyRef:
              name: huggingface
              key: token.txt
        - name: GIT_TOKEN
          valueFrom: 
            secretKeyRef:
              name: github
              key: gittoken.txt
        resources:
          limits:
            cpu: "8"
            ephemeral-storage: 400Gi
            google.com/tpu: "4"
            memory: 400G
          requests:
            cpu: "8"
            ephemeral-storage: 250Gi
            google.com/tpu: "4"
            memory: 200G
      nodeSelector:
        cloud.google.com/gke-tpu-accelerator: tpu-v4-podslice
        cloud.google.com/gke-tpu-topology: 4x4x8
